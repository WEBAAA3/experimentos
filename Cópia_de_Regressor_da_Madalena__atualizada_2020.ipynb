{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WEBAAA3/experimentos/blob/main/C%C3%B3pia_de_Regressor_da_Madalena__atualizada_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPqNrUHgIoQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bebeb6-b24b-4671-9981-292d15e027b5"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# Carregar biblioteca para usar o drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Autorização\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            " \u001b[0m\u001b[01;34m3classes\u001b[0m/\n",
            " 3classessimuladovgg16.csv\n",
            " 3classessimuladovgg16.h5\n",
            " 3classes.zip\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            " \u001b[01;34mdatasets_mestrado\u001b[0m/\n",
            " df_cer_resnet50real.csv\n",
            " df_err_resnet50real.csv\n",
            " df_err_simuladovgg16.csv\n",
            "'FINAL MESTRADO.ipynb'\n",
            "'Geração de Resultados.ipynb'\n",
            "'Metodologia ImageDataGenerator Imagens.ipynb'\n",
            " misturadoesnet50.h5\n",
            " misturadoinceptionv3.csv\n",
            " misturadoinceptionv3.h5\n",
            " misturadoresnet50.csv\n",
            " misturadoresnet50.h5\n",
            " misturadovgg16_2.h5\n",
            " misturadovgg16.csv\n",
            " misturadovgg16.h5\n",
            " realinceptionv3.csv\n",
            " realinceptionv3.h5\n",
            " realinceptionv3_v2.csv\n",
            " realinceptionv3_v2.h5\n",
            " realresnet50.csv\n",
            " realresnet50.h5\n",
            " realvgg16_2.h5\n",
            " realvgg16.csv\n",
            " realvgg16.h5\n",
            " realvgg16_v2.csv\n",
            " realvgg16_v3.csv\n",
            " realvgg16_v3.h5\n",
            " sep_h.zip\n",
            " simuadovgg16_v2.csv\n",
            " simuladoinceptionv3.csv\n",
            " simuladoinceptionv3.h5\n",
            " simuladoresnet50.csv\n",
            " simuladoresnet50.h5\n",
            " simuladovgg16.csv\n",
            " simuladovgg16.h5\n",
            " simuladovgg16_v2.h5\n",
            " tentativa1realapenas230inceptionv3sep_h.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCTC-BkiMpOi"
      },
      "source": [
        "#diretorios mãe das imagens treino\n",
        "ndir=3\n",
        "dir1='/content/drive/My Drive/dataset/treino/grosso'\n",
        "dir2='/content/drive/My Drive/dataset/treino/ideal'\n",
        "dir3='/content/drive/My Drive/dataset/treino/fino'\n",
        "mypath=np.array([ dir1, dir2, dir3 ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihk78A8tO7w0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7295de5a-dbad-465e-ae0b-51eada669679"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "train_diretorios = np.array([], dtype=object)\n",
        "train_porcentagens = np.array([[],[],[]])\n",
        "cont=0\n",
        "for dir_index in range(ndir):\n",
        "  for image_name in listdir(mypath[dir_index]):\n",
        "    train_diretorios=np.append(train_diretorios,join(str(mypath[dir_index]), str(image_name)) )\n",
        "    image_name=image_name.replace('.', '-')\n",
        "    image_name=image_name.replace(' ', '-')\n",
        "    splitado =image_name.split(\"-\")\n",
        "    train_porcentagens = np.append(train_porcentagens, [[splitado[0]], [splitado[1]], [splitado[2]]], axis=1)\n",
        "    cont=cont+1\n",
        "print(cont)\n",
        "train_porcentagens = np.asarray(train_porcentagens.astype(np.float))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxBva0JZPqWg"
      },
      "source": [
        "train_data_frame = np.zeros((cont,4), dtype=object)\n",
        "\n",
        "train_data_frame[:,0]= np.asarray(train_diretorios)\n",
        "train_data_frame[:,1]= np.asarray(train_porcentagens[0,:].astype(np.float32))\n",
        "train_data_frame[:,2]= np.asarray(train_porcentagens[1,:].astype(np.float32))\n",
        "train_data_frame[:,3]= np.asarray(train_porcentagens[2,:].astype(np.float32))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SQN3o8MRgEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "887792a9-20df-4296-8b42-2579a7589977"
      },
      "source": [
        "train_data_frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['/content/drive/My Drive/dataset/treino/grosso/63-15-23.png',\n",
              "        63.0, 15.0, 23.0],\n",
              "       ['/content/drive/My Drive/dataset/treino/grosso/60-25-16.png',\n",
              "        60.0, 25.0, 16.0],\n",
              "       ['/content/drive/My Drive/dataset/treino/grosso/68-21-11.png',\n",
              "        68.0, 21.0, 11.0],\n",
              "       ...,\n",
              "       ['/content/drive/My Drive/dataset/treino/fino/5-6-89.png', 5.0,\n",
              "        6.0, 89.0],\n",
              "       ['/content/drive/My Drive/dataset/treino/fino/7-6-88.png', 7.0,\n",
              "        6.0, 88.0],\n",
              "       ['/content/drive/My Drive/dataset/treino/fino/4-6-89.png', 4.0,\n",
              "        6.0, 89.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEqoPAepblH-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "5615f37f-a771-42cb-f5c8-a71130c660ec"
      },
      "source": [
        "ndir=3\n",
        "dir1='/content/drive/My Drive/dataset/validacao/grosso'\n",
        "dir2='/content/drive/My Drive/dataset/validacao/ideal'\n",
        "dir3='/content/drive/My Drive/dataset/validacao/fino'\n",
        "mypath=np.array([ dir1, dir2, dir3 ])\n",
        "val_diretorios = np.array([], dtype=object)\n",
        "val_porcentagens = np.array([[],[],[]])\n",
        "cont=0\n",
        "for dir_index in range(ndir):\n",
        "  for image_name in listdir(mypath[dir_index]):\n",
        "    val_diretorios=np.append(val_diretorios,join(str(mypath[dir_index]), str(image_name)) )\n",
        "    image_name=image_name.replace('.', '-')\n",
        "    splitado =image_name.split(\"-\")\n",
        "    image_name=image_name.replace(' ', '-')\n",
        "    val_porcentagens = np.append(val_porcentagens, [[splitado[0]], [splitado[1]], [splitado[2]]], axis=1)\n",
        "    cont=cont+1\n",
        "print(cont)\n",
        "val_porcentagens = np.asarray(val_porcentagens.astype(np.float))\n",
        "\n",
        "val_data_frame = np.zeros((cont,4), dtype=object)\n",
        "\n",
        "val_data_frame[:,0]= np.asarray(val_diretorios)\n",
        "val_data_frame[:,1]= np.asarray(val_porcentagens[0,:].astype(np.float32))\n",
        "val_data_frame[:,2]= np.asarray(val_porcentagens[1,:].astype(np.float32))\n",
        "val_data_frame[:,3]= np.asarray(val_porcentagens[2,:].astype(np.float32))\n",
        "\n",
        "print(val_data_frame)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "738\n",
            "[['/content/drive/My Drive/dataset/validacao/grosso/91-9-0.png' 91.0 9.0\n",
            "  0.0]\n",
            " ['/content/drive/My Drive/dataset/validacao/grosso/99-1-0.png' 99.0 1.0\n",
            "  0.0]\n",
            " ['/content/drive/My Drive/dataset/validacao/grosso/90-10-0.png' 90.0\n",
            "  10.0 0.0]\n",
            " ...\n",
            " ['/content/drive/My Drive/dataset/validacao/fino/0-49-51-936.png' 0.0\n",
            "  49.0 51.0]\n",
            " ['/content/drive/My Drive/dataset/validacao/fino/0-48-52-970.png' 0.0\n",
            "  48.0 52.0]\n",
            " ['/content/drive/My Drive/dataset/validacao/fino/0-40-60-975.png' 0.0\n",
            "  40.0 60.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK88x639d4zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "d52f2a06-80a4-48f5-debd-c114c3a898d2"
      },
      "source": [
        "treinodic = {'diretorio': train_diretorios, 'p1': train_porcentagens[0,:],'p2': train_porcentagens[1,:],'p3': train_porcentagens[2,:] }\n",
        "treino_dataframe= pd.DataFrame(data=treinodic)\n",
        "print(treino_dataframe)\n",
        "\n",
        "valdic = {'diretorio': val_diretorios, 'p1': val_porcentagens[0,:],'p2': val_porcentagens[1,:],'p3': val_porcentagens[2,:] }\n",
        "val_dataframe= pd.DataFrame(data=valdic)\n",
        "print(val_dataframe)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              diretorio    p1    p2    p3\n",
            "0     /content/drive/My Drive/dataset/treino/grosso/...  63.0  15.0  23.0\n",
            "1     /content/drive/My Drive/dataset/treino/grosso/...  60.0  25.0  16.0\n",
            "2     /content/drive/My Drive/dataset/treino/grosso/...  68.0  21.0  11.0\n",
            "3     /content/drive/My Drive/dataset/treino/grosso/...  63.0  21.0  15.0\n",
            "4     /content/drive/My Drive/dataset/treino/grosso/...  65.0  14.0  20.0\n",
            "...                                                 ...   ...   ...   ...\n",
            "5480  /content/drive/My Drive/dataset/treino/fino/7-...   7.0   6.0  87.0\n",
            "5481  /content/drive/My Drive/dataset/treino/fino/3-...   3.0   7.0  90.0\n",
            "5482  /content/drive/My Drive/dataset/treino/fino/5-...   5.0   6.0  89.0\n",
            "5483  /content/drive/My Drive/dataset/treino/fino/7-...   7.0   6.0  88.0\n",
            "5484  /content/drive/My Drive/dataset/treino/fino/4-...   4.0   6.0  89.0\n",
            "\n",
            "[5485 rows x 4 columns]\n",
            "                                             diretorio    p1    p2    p3\n",
            "0    /content/drive/My Drive/dataset/validacao/gros...  91.0   9.0   0.0\n",
            "1    /content/drive/My Drive/dataset/validacao/gros...  99.0   1.0   0.0\n",
            "2    /content/drive/My Drive/dataset/validacao/gros...  90.0  10.0   0.0\n",
            "3    /content/drive/My Drive/dataset/validacao/gros...  98.0   2.0   0.0\n",
            "4    /content/drive/My Drive/dataset/validacao/gros...  92.0   8.0   0.0\n",
            "..                                                 ...   ...   ...   ...\n",
            "733  /content/drive/My Drive/dataset/validacao/fino...   0.0  43.0  57.0\n",
            "734  /content/drive/My Drive/dataset/validacao/fino...   0.0  41.0  59.0\n",
            "735  /content/drive/My Drive/dataset/validacao/fino...   0.0  49.0  51.0\n",
            "736  /content/drive/My Drive/dataset/validacao/fino...   0.0  48.0  52.0\n",
            "737  /content/drive/My Drive/dataset/validacao/fino...   0.0  40.0  60.0\n",
            "\n",
            "[738 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjaLgX6hchLj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d5bfc60f-bb6a-4543-c790-c6ba53f0d30b"
      },
      "source": [
        "trdata = ImageDataGenerator(vertical_flip = True,\n",
        "                            horizontal_flip = True,\n",
        "                            rotation_range = 90)\n",
        "\n",
        "traindata = trdata.flow_from_dataframe(dataframe = treino_dataframe,\n",
        "                                      directory=None,\n",
        "                                      x_col='diretorio',\n",
        "                                      y_col=['p1', 'p2', 'p3'],\n",
        "                                      class_mode='raw',\n",
        "                                      target_size= (224,224),shuffle = True)\n",
        "valdata = ImageDataGenerator()\n",
        "\n",
        "valdata = valdata.flow_from_dataframe(dataframe = val_dataframe,\n",
        "                                      directory=None,\n",
        "                                      x_col='diretorio',\n",
        "                                      y_col=['p1', 'p2', 'p3'],\n",
        "                                      class_mode='raw',\n",
        "                                      target_size= (224,224),shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5485 validated image filenames.\n",
            "Found 738 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfA_ASQkgCwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "efa8a0bc-1bad-4e5a-fbe5-d14663668df7"
      },
      "source": [
        "\n",
        "# path to the model weights files.\n",
        "weights_path = '../keras/examples/vgg16_weights.h5'\n",
        "top_model_weights_path = 'fc_model.h5'\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 224, 224\n",
        "# build the VGG16 network\n",
        "model = applications.VGG16(weights='imagenet', include_top=False)\n",
        "print('Model loaded.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67FdNTAGhCty",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "afbf25fc-5d1b-4670-d41e-9c0257fd77fd"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "# build a classifier model to put on top of the convolutional model\n",
        "\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten())\n",
        "top_model.add(Dense(units=4096,activation=\"relu\"))\n",
        "top_model.add(Dense(units=4096,activation=\"relu\"))\n",
        "top_model.add(Dense(units=3, activation=\"relu\"))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "##############################top_model.load_weights(top_model_weights_path)\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
        "\n",
        "print(np.transpose(base_model.layers))\n",
        "print(np.transpose(top_model.layers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f1dd057f400>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd057f438>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd057f860>\n",
            " <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1dd057fc50>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd0576780>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd05845f8>\n",
            " <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1dd0584a20>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd050d240>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd050de48>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd05134e0>\n",
            " <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1dd0513d30>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd051e898>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd0526710>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd05267b8>\n",
            " <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1dd052f710>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd052fef0>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd0535d68>\n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1dd053f748>\n",
            " <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1dd053fa58>]\n",
            "[<tensorflow.python.keras.layers.core.Flatten object at 0x7f1dd04d49b0>\n",
            " <tensorflow.python.keras.layers.core.Dense object at 0x7f1dd04d4940>\n",
            " <tensorflow.python.keras.layers.core.Dense object at 0x7f1dd04d4b70>\n",
            " <tensorflow.python.keras.layers.core.Dense object at 0x7f1dd04d4e10>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AkFcIfQhHXZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "1052642f-7cf3-418d-9e35-2be4a7c3b3f3"
      },
      "source": [
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:18]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(lr=0.001)\n",
        "\n",
        "\n",
        "model.compile(optimizer= opt,\n",
        "              loss= keras.losses.mean_squared_error,\n",
        "              metrics= ['mean_squared_error'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 3)                 119558147 \n",
            "=================================================================\n",
            "Total params: 134,272,835\n",
            "Trainable params: 119,558,147\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z6lIJWhhQvu"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/batata2_1.h5\",\n",
        "                             monitor='val_mean_squared_error',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto',\n",
        "                             save_freq=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVUo2S0qigGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "b11b9ccf-c89b-4adc-a5b5-b3471a35c5ff"
      },
      "source": [
        "#hist = model.fit(traindata, steps_per_epoch=100, epochs=100,verbose=1, validation_data=valdata, validation_steps=100, validation_freq=1)\n",
        "#hist = model.fit(traindata, epochs=2, validation_data=valdata)\n",
        "\n",
        "model.fit(\n",
        "    x=traindata, y=None, batch_size=None, epochs=100, verbose=1, callbacks=None,\n",
        "    validation_split=0.0, validation_data=valdata, shuffle=True, class_weight=None,\n",
        "    sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
        "    validation_steps=None, validation_freq=1, max_queue_size=10, workers=1,\n",
        "    use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "172/172 [==============================] - 2725s 16s/step - loss: 8876.6885 - mean_squared_error: 8876.6885 - val_loss: 2027.3696 - val_mean_squared_error: 2027.3696\n",
            "Epoch 2/100\n",
            " 77/172 [============>.................] - ETA: 40s - loss: 1956.6676 - mean_squared_error: 1956.6676"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b7e78a19e477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     use_multiprocessing=False)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm2qq4gU5k9o"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Epoch 1/100\n",
        "  3/100 [..............................] - ETA: 37:37 - loss: 182505.5285 - mean_squared_error: 182505.5156\n",
        "\n",
        "  Epoch 1/100\n",
        "100/100 [==============================] - 95s 946ms/step - loss: 17652.9032 - mean_squared_error: 17652.8984 - val_loss: 237.0197 - val_mean_squared_error: 270.8129\n",
        "\n",
        "Epoch 00001: val_mean_squared_error improved from inf to 270.81290, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 2/100\n",
        "100/100 [==============================] - 89s 892ms/step - loss: 172.6693 - mean_squared_error: 172.5703 - val_loss: 216.6181 - val_mean_squared_error: 229.3025\n",
        "\n",
        "Epoch 00002: val_mean_squared_error improved from 270.81290 to 229.30254, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 3/100\n",
        "100/100 [==============================] - 89s 891ms/step - loss: 139.1387 - mean_squared_error: 139.1387 - val_loss: 163.3814 - val_mean_squared_error: 206.4948\n",
        "\n",
        "Epoch 00003: val_mean_squared_error improved from 229.30254 to 206.49477, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 4/100\n",
        "100/100 [==============================] - 89s 894ms/step - loss: 132.2967 - mean_squared_error: 132.8982 - val_loss: 147.6147 - val_mean_squared_error: 176.5522\n",
        "\n",
        "Epoch 00004: val_mean_squared_error improved from 206.49477 to 176.55219, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 5/100\n",
        "100/100 [==============================] - 89s 889ms/step - loss: 132.5944 - mean_squared_error: 132.5944 - val_loss: 167.7099 - val_mean_squared_error: 156.5229\n",
        "\n",
        "Epoch 00005: val_mean_squared_error improved from 176.55219 to 156.52290, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 6/100\n",
        "100/100 [==============================] - 91s 908ms/step - loss: 118.9664 - mean_squared_error: 118.4360 - val_loss: 170.3504 - val_mean_squared_error: 198.3201\n",
        "\n",
        "Epoch 00006: val_mean_squared_error did not improve from 156.52290\n",
        "Epoch 7/100\n",
        "100/100 [==============================] - 87s 869ms/step - loss: 116.5958 - mean_squared_error: 116.5958 - val_loss: 225.8722 - val_mean_squared_error: 176.6178\n",
        "\n",
        "Epoch 00007: val_mean_squared_error did not improve from 156.52290\n",
        "Epoch 8/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 117.8887 - mean_squared_error: 117.8936 - val_loss: 131.5569 - val_mean_squared_error: 147.7527\n",
        "\n",
        "Epoch 00008: val_mean_squared_error improved from 156.52290 to 147.75269, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 9/100\n",
        "100/100 [==============================] - 90s 904ms/step - loss: 109.5316 - mean_squared_error: 109.5315 - val_loss: 94.3736 - val_mean_squared_error: 144.9152\n",
        "\n",
        "Epoch 00009: val_mean_squared_error improved from 147.75269 to 144.91519, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 10/100\n",
        "100/100 [==============================] - 91s 907ms/step - loss: 105.4805 - mean_squared_error: 105.5952 - val_loss: 169.3132 - val_mean_squared_error: 148.0269\n",
        "\n",
        "Epoch 00010: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 11/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 101.9292 - mean_squared_error: 101.9822 - val_loss: 131.5695 - val_mean_squared_error: 161.8443\n",
        "\n",
        "Epoch 00011: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 12/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 113.7075 - mean_squared_error: 113.7075 - val_loss: 518.4127 - val_mean_squared_error: 204.2226\n",
        "\n",
        "Epoch 00012: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 13/100\n",
        "100/100 [==============================] - 90s 902ms/step - loss: 105.2685 - mean_squared_error: 105.6216 - val_loss: 169.0555 - val_mean_squared_error: 146.8615\n",
        "\n",
        "Epoch 00013: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 14/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 107.6383 - mean_squared_error: 107.6383 - val_loss: 198.8984 - val_mean_squared_error: 160.9733\n",
        "\n",
        "Epoch 00014: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 15/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 104.0012 - mean_squared_error: 104.0012 - val_loss: 177.9411 - val_mean_squared_error: 174.9219\n",
        "\n",
        "Epoch 00015: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 16/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 103.2039 - mean_squared_error: 103.2846 - val_loss: 146.2189 - val_mean_squared_error: 171.8732\n",
        "\n",
        "Epoch 00016: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 17/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 103.2729 - mean_squared_error: 103.4505 - val_loss: 91.4709 - val_mean_squared_error: 150.4377\n",
        "\n",
        "Epoch 00017: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 18/100\n",
        "100/100 [==============================] - 87s 867ms/step - loss: 102.2450 - mean_squared_error: 102.1788 - val_loss: 199.8296 - val_mean_squared_error: 192.1467\n",
        "\n",
        "Epoch 00018: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 19/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 101.7425 - mean_squared_error: 101.7425 - val_loss: 158.5723 - val_mean_squared_error: 155.1729\n",
        "\n",
        "Epoch 00019: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 20/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 105.1283 - mean_squared_error: 105.3039 - val_loss: 249.0961 - val_mean_squared_error: 160.5862\n",
        "\n",
        "Epoch 00020: val_mean_squared_error did not improve from 144.91519\n",
        "Epoch 21/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 98.8379 - mean_squared_error: 98.7445 - val_loss: 211.0611 - val_mean_squared_error: 141.5683\n",
        "\n",
        "Epoch 00021: val_mean_squared_error improved from 144.91519 to 141.56825, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 22/100\n",
        "100/100 [==============================] - 89s 886ms/step - loss: 100.5252 - mean_squared_error: 100.5252 - val_loss: 149.7976 - val_mean_squared_error: 159.6182\n",
        "\n",
        "Epoch 00022: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 23/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 98.2552 - mean_squared_error: 98.2552 - val_loss: 317.6446 - val_mean_squared_error: 179.8645\n",
        "\n",
        "Epoch 00023: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 24/100\n",
        "100/100 [==============================] - 85s 846ms/step - loss: 102.9023 - mean_squared_error: 102.8056 - val_loss: 260.6518 - val_mean_squared_error: 150.8395\n",
        "\n",
        "Epoch 00024: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 25/100\n",
        "100/100 [==============================] - 89s 889ms/step - loss: 94.0773 - mean_squared_error: 94.0773 - val_loss: 179.8786 - val_mean_squared_error: 192.1340\n",
        "\n",
        "Epoch 00025: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 26/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 98.9999 - mean_squared_error: 99.1396 - val_loss: 162.2632 - val_mean_squared_error: 146.2075\n",
        "\n",
        "Epoch 00026: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 27/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 97.9192 - mean_squared_error: 97.6386 - val_loss: 227.6456 - val_mean_squared_error: 145.9790\n",
        "\n",
        "Epoch 00027: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 28/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 96.7468 - mean_squared_error: 96.7468 - val_loss: 146.6342 - val_mean_squared_error: 148.8845\n",
        "\n",
        "Epoch 00028: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 29/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 96.5028 - mean_squared_error: 96.5027 - val_loss: 178.6540 - val_mean_squared_error: 174.5326\n",
        "\n",
        "Epoch 00029: val_mean_squared_error did not improve from 141.56825\n",
        "Epoch 30/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 88.8498 - mean_squared_error: 88.9319 - val_loss: 155.6310 - val_mean_squared_error: 136.1385\n",
        "\n",
        "Epoch 00030: val_mean_squared_error improved from 141.56825 to 136.13855, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 31/100\n",
        "100/100 [==============================] - 88s 883ms/step - loss: 90.7713 - mean_squared_error: 90.4329 - val_loss: 84.4694 - val_mean_squared_error: 122.6177\n",
        "\n",
        "Epoch 00031: val_mean_squared_error improved from 136.13855 to 122.61771, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 32/100\n",
        "100/100 [==============================] - 88s 883ms/step - loss: 92.2507 - mean_squared_error: 92.3908 - val_loss: 139.6014 - val_mean_squared_error: 147.0739\n",
        "\n",
        "Epoch 00032: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 33/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 92.5124 - mean_squared_error: 92.5124 - val_loss: 136.3738 - val_mean_squared_error: 159.6862\n",
        "\n",
        "Epoch 00033: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 34/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 89.7178 - mean_squared_error: 89.7178 - val_loss: 108.5132 - val_mean_squared_error: 133.5908\n",
        "\n",
        "Epoch 00034: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 35/100\n",
        "100/100 [==============================] - 85s 850ms/step - loss: 91.4552 - mean_squared_error: 91.5693 - val_loss: 136.3136 - val_mean_squared_error: 141.4324\n",
        "\n",
        "Epoch 00035: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 36/100\n",
        "100/100 [==============================] - 84s 843ms/step - loss: 93.2893 - mean_squared_error: 93.2894 - val_loss: 28.8622 - val_mean_squared_error: 138.3905\n",
        "\n",
        "Epoch 00036: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 37/100\n",
        "100/100 [==============================] - 88s 876ms/step - loss: 95.2366 - mean_squared_error: 95.1514 - val_loss: 203.3713 - val_mean_squared_error: 153.5447\n",
        "\n",
        "Epoch 00037: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 38/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 96.3000 - mean_squared_error: 96.3946 - val_loss: 138.7735 - val_mean_squared_error: 137.9995\n",
        "\n",
        "Epoch 00038: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 39/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 94.3477 - mean_squared_error: 94.3478 - val_loss: 135.7009 - val_mean_squared_error: 143.9727\n",
        "\n",
        "Epoch 00039: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 40/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 89.9602 - mean_squared_error: 89.9602 - val_loss: 152.1436 - val_mean_squared_error: 137.8835\n",
        "\n",
        "Epoch 00040: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 41/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 87.8278 - mean_squared_error: 87.7080 - val_loss: 120.6366 - val_mean_squared_error: 142.2862\n",
        "\n",
        "Epoch 00041: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 42/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 87.7954 - mean_squared_error: 87.7953 - val_loss: 53.6568 - val_mean_squared_error: 147.4459\n",
        "\n",
        "Epoch 00042: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 43/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 90.2379 - mean_squared_error: 90.3082 - val_loss: 140.8708 - val_mean_squared_error: 171.1644\n",
        "\n",
        "Epoch 00043: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 44/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 87.0963 - mean_squared_error: 86.6679 - val_loss: 112.3512 - val_mean_squared_error: 130.1959\n",
        "\n",
        "Epoch 00044: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 45/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 88.2070 - mean_squared_error: 88.2070 - val_loss: 186.4282 - val_mean_squared_error: 170.6810\n",
        "\n",
        "Epoch 00045: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 46/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 88.1383 - mean_squared_error: 88.3472 - val_loss: 100.2960 - val_mean_squared_error: 167.2465\n",
        "\n",
        "Epoch 00046: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 47/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 88.6681 - mean_squared_error: 88.6874 - val_loss: 110.4232 - val_mean_squared_error: 139.3490\n",
        "\n",
        "Epoch 00047: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 48/100\n",
        "100/100 [==============================] - 86s 855ms/step - loss: 89.6725 - mean_squared_error: 89.6724 - val_loss: 51.1523 - val_mean_squared_error: 154.8293\n",
        "\n",
        "Epoch 00048: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 49/100\n",
        "100/100 [==============================] - 87s 872ms/step - loss: 86.3863 - mean_squared_error: 86.3863 - val_loss: 93.9703 - val_mean_squared_error: 139.3766\n",
        "\n",
        "Epoch 00049: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 50/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 85.5949 - mean_squared_error: 85.7805 - val_loss: 110.3566 - val_mean_squared_error: 146.3417\n",
        "\n",
        "Epoch 00050: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 51/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 84.1302 - mean_squared_error: 84.2788 - val_loss: 99.1934 - val_mean_squared_error: 134.8722\n",
        "\n",
        "Epoch 00051: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 52/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 84.9524 - mean_squared_error: 84.9523 - val_loss: 114.2134 - val_mean_squared_error: 126.3478\n",
        "\n",
        "Epoch 00052: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 53/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 85.4165 - mean_squared_error: 85.4730 - val_loss: 99.3955 - val_mean_squared_error: 136.7372\n",
        "\n",
        "Epoch 00053: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 54/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 82.9225 - mean_squared_error: 82.9225 - val_loss: 37.8816 - val_mean_squared_error: 152.7024\n",
        "\n",
        "Epoch 00054: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 55/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 83.2708 - mean_squared_error: 83.5888 - val_loss: 177.7787 - val_mean_squared_error: 146.5317\n",
        "\n",
        "Epoch 00055: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 56/100\n",
        "100/100 [==============================] - 90s 896ms/step - loss: 83.8445 - mean_squared_error: 84.1679 - val_loss: 130.3571 - val_mean_squared_error: 148.6455\n",
        "\n",
        "Epoch 00056: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 57/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 87.1689 - mean_squared_error: 87.0141 - val_loss: 120.2918 - val_mean_squared_error: 140.8648\n",
        "\n",
        "Epoch 00057: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 58/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 83.5469 - mean_squared_error: 83.5469 - val_loss: 112.5178 - val_mean_squared_error: 129.3671\n",
        "\n",
        "Epoch 00058: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 59/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 86.3961 - mean_squared_error: 86.3961 - val_loss: 107.7046 - val_mean_squared_error: 127.9407\n",
        "\n",
        "Epoch 00059: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 60/100\n",
        "100/100 [==============================] - 85s 849ms/step - loss: 85.0129 - mean_squared_error: 85.0913 - val_loss: 592.3145 - val_mean_squared_error: 165.9738\n",
        "\n",
        "Epoch 00060: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 61/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 84.7631 - mean_squared_error: 84.6617 - val_loss: 161.7522 - val_mean_squared_error: 136.4062\n",
        "\n",
        "Epoch 00061: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 62/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 87.8748 - mean_squared_error: 87.8749 - val_loss: 201.6409 - val_mean_squared_error: 164.1571\n",
        "\n",
        "Epoch 00062: val_mean_squared_error did not improve from 122.61771\n",
        "Epoch 63/100\n",
        "100/100 [==============================] - 86s 855ms/step - loss: 81.4599 - mean_squared_error: 81.5946 - val_loss: 108.8826 - val_mean_squared_error: 121.1574\n",
        "\n",
        "Epoch 00063: val_mean_squared_error improved from 122.61771 to 121.15739, saving model to /content/drive/My Drive/douglas_rodando_regressao_1.h5\n",
        "Epoch 64/100\n",
        "100/100 [==============================] - 89s 890ms/step - loss: 80.2573 - mean_squared_error: 80.2573 - val_loss: 173.9463 - val_mean_squared_error: 175.4082\n",
        "\n",
        "Epoch 00064: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 65/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 80.1701 - mean_squared_error: 80.1702 - val_loss: 126.6799 - val_mean_squared_error: 145.7564\n",
        "\n",
        "Epoch 00065: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 66/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 82.1589 - mean_squared_error: 81.9012 - val_loss: 60.8536 - val_mean_squared_error: 145.1938\n",
        "\n",
        "Epoch 00066: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 67/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 83.1624 - mean_squared_error: 83.4119 - val_loss: 129.8324 - val_mean_squared_error: 131.5730\n",
        "\n",
        "Epoch 00067: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 68/100\n",
        "100/100 [==============================] - 90s 895ms/step - loss: 83.1950 - mean_squared_error: 83.1950 - val_loss: 148.4184 - val_mean_squared_error: 135.0993\n",
        "\n",
        "Epoch 00068: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 69/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 80.3646 - mean_squared_error: 80.1852 - val_loss: 134.2668 - val_mean_squared_error: 147.6110\n",
        "\n",
        "Epoch 00069: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 70/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 79.6663 - mean_squared_error: 79.6663 - val_loss: 97.6641 - val_mean_squared_error: 133.5054\n",
        "\n",
        "Epoch 00070: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 71/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 82.6797 - mean_squared_error: 82.7506 - val_loss: 194.6302 - val_mean_squared_error: 153.5469\n",
        "\n",
        "Epoch 00071: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 72/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 81.5583 - mean_squared_error: 81.6480 - val_loss: 47.1931 - val_mean_squared_error: 129.9442\n",
        "\n",
        "Epoch 00072: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 73/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 82.7723 - mean_squared_error: 82.8356 - val_loss: 138.1914 - val_mean_squared_error: 142.0270\n",
        "\n",
        "Epoch 00073: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 74/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 79.4150 - mean_squared_error: 79.4150 - val_loss: 107.0678 - val_mean_squared_error: 121.8993\n",
        "\n",
        "Epoch 00074: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 75/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 83.3441 - mean_squared_error: 83.1770 - val_loss: 171.1540 - val_mean_squared_error: 159.7241\n",
        "\n",
        "Epoch 00075: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 76/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 81.4262 - mean_squared_error: 81.4262 - val_loss: 128.5634 - val_mean_squared_error: 141.9126\n",
        "\n",
        "Epoch 00076: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 77/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 82.6330 - mean_squared_error: 82.6330 - val_loss: 213.2654 - val_mean_squared_error: 125.5165\n",
        "\n",
        "Epoch 00077: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 78/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 79.7721 - mean_squared_error: 79.5258 - val_loss: 75.2382 - val_mean_squared_error: 134.3553\n",
        "\n",
        "Epoch 00078: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 79/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 79.0819 - mean_squared_error: 78.9304 - val_loss: 130.3294 - val_mean_squared_error: 140.6560\n",
        "\n",
        "Epoch 00079: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 80/100\n",
        "100/100 [==============================] - 88s 881ms/step - loss: 80.8808 - mean_squared_error: 80.9978 - val_loss: 121.0602 - val_mean_squared_error: 137.4962\n",
        "\n",
        "Epoch 00080: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 81/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 84.0198 - mean_squared_error: 84.0198 - val_loss: 91.8548 - val_mean_squared_error: 137.2910\n",
        "\n",
        "Epoch 00081: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 82/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 80.2456 - mean_squared_error: 80.2456 - val_loss: 134.6229 - val_mean_squared_error: 131.2388\n",
        "\n",
        "Epoch 00082: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 83/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 82.6226 - mean_squared_error: 82.7113 - val_loss: 144.1435 - val_mean_squared_error: 142.2198\n",
        "\n",
        "Epoch 00083: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 84/100\n",
        "100/100 [==============================] - 85s 848ms/step - loss: 83.6271 - mean_squared_error: 83.7752 - val_loss: 231.5086 - val_mean_squared_error: 148.2286\n",
        "\n",
        "Epoch 00084: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 85/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 81.0734 - mean_squared_error: 81.0734 - val_loss: 156.5076 - val_mean_squared_error: 154.5442\n",
        "\n",
        "Epoch 00085: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 86/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 79.2359 - mean_squared_error: 79.2317 - val_loss: 253.8297 - val_mean_squared_error: 141.9249\n",
        "\n",
        "Epoch 00086: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 87/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 76.7469 - mean_squared_error: 76.7842 - val_loss: 217.6370 - val_mean_squared_error: 161.7032\n",
        "\n",
        "Epoch 00087: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 88/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 80.2916 - mean_squared_error: 80.2916 - val_loss: 134.5693 - val_mean_squared_error: 154.4918\n",
        "\n",
        "Epoch 00088: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 89/100\n",
        "100/100 [==============================] - 85s 850ms/step - loss: 79.4005 - mean_squared_error: 79.3588 - val_loss: 138.0084 - val_mean_squared_error: 141.1820\n",
        "\n",
        "Epoch 00089: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 90/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 80.7379 - mean_squared_error: 80.7379 - val_loss: 280.0484 - val_mean_squared_error: 147.8407\n",
        "\n",
        "Epoch 00090: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 91/100\n",
        "100/100 [==============================] - 86s 855ms/step - loss: 82.6851 - mean_squared_error: 82.8236 - val_loss: 123.0392 - val_mean_squared_error: 151.2570\n",
        "\n",
        "Epoch 00091: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 92/100\n",
        "100/100 [==============================] - 87s 867ms/step - loss: 80.3200 - mean_squared_error: 80.3146 - val_loss: 117.4240 - val_mean_squared_error: 127.9863\n",
        "\n",
        "Epoch 00092: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 93/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 75.8694 - mean_squared_error: 75.8694 - val_loss: 143.7567 - val_mean_squared_error: 154.4771\n",
        "\n",
        "Epoch 00093: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 94/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 71.3797 - mean_squared_error: 71.3797 - val_loss: 132.5136 - val_mean_squared_error: 145.0684\n",
        "\n",
        "Epoch 00094: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 95/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 80.2685 - mean_squared_error: 80.5120 - val_loss: 170.7236 - val_mean_squared_error: 151.6739\n",
        "\n",
        "Epoch 00095: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 96/100\n",
        "100/100 [==============================] - 85s 847ms/step - loss: 80.4327 - mean_squared_error: 80.4193 - val_loss: 13.0449 - val_mean_squared_error: 163.9333\n",
        "\n",
        "Epoch 00096: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 97/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 79.4446 - mean_squared_error: 79.4446 - val_loss: 98.3084 - val_mean_squared_error: 128.9107\n",
        "\n",
        "Epoch 00097: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 98/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 72.7111 - mean_squared_error: 72.5000 - val_loss: 141.1872 - val_mean_squared_error: 133.1441\n",
        "\n",
        "Epoch 00098: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 99/100\n",
        "100/100 [==============================] - 89s 890ms/step - loss: 75.2027 - mean_squared_error: 75.3401 - val_loss: 145.7193 - val_mean_squared_error: 141.7056\n",
        "\n",
        "Epoch 00099: val_mean_squared_error did not improve from 121.15739\n",
        "Epoch 100/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 79.3842 - mean_squared_error: 79.3842 - val_loss: 119.0853 - val_mean_squared_error: 146.7905\n",
        "\n",
        "Epoch 00100: val_mean_squared_error did not improve from 121.15739"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx_inceSkgQY"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/regressao_lr1e-3_adam_metricaloss_mse_ultimacamada_relu/julio_rodando_regressao_2.h5\",\n",
        "                             monitor='val_mean_squared_error',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto',\n",
        "                             period=1)\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "modelrecuperado= load_model(\"/content/drive/My Drive/regressao_lr1e-3_adam_metricaloss_mse_ultimacamada_relu/julio_rodando_regressao_1.h5\")\n",
        "\n",
        "for layer in modelrecuperado.layers[:18]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "hist = modelrecuperado.fit_generator(steps_per_epoch=100,\n",
        "                           generator=traindata,\n",
        "                           validation_data= valdata,\n",
        "                           validation_steps=100,\n",
        "                           epochs=100,\n",
        "                           callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28s-j2lsLk3A"
      },
      "source": [
        "Epoch 1/100\n",
        "100/100 [==============================] - 898s 9s/step - loss: 82.2740 - mean_squared_error: 82.2740 - val_loss: 125.6732 - val_mean_squared_error: 139.5871\n",
        "\n",
        "Epoch 00001: val_mean_squared_error improved from inf to 139.58707, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 2/100\n",
        "100/100 [==============================] - 533s 5s/step - loss: 81.7326 - mean_squared_error: 81.7290 - val_loss: 149.9187 - val_mean_squared_error: 140.3158\n",
        "\n",
        "Epoch 00002: val_mean_squared_error did not improve from 139.58707\n",
        "Epoch 3/100\n",
        "100/100 [==============================] - 85s 846ms/step - loss: 83.4422 - mean_squared_error: 83.6139 - val_loss: 140.2148 - val_mean_squared_error: 142.5880\n",
        "\n",
        "Epoch 00003: val_mean_squared_error did not improve from 139.58707\n",
        "Epoch 4/100\n",
        "100/100 [==============================] - 85s 848ms/step - loss: 78.6365 - mean_squared_error: 78.6365 - val_loss: 137.2894 - val_mean_squared_error: 147.8375\n",
        "\n",
        "Epoch 00004: val_mean_squared_error did not improve from 139.58707\n",
        "Epoch 5/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 83.4997 - mean_squared_error: 83.6898 - val_loss: 162.8138 - val_mean_squared_error: 130.6481\n",
        "\n",
        "Epoch 00005: val_mean_squared_error improved from 139.58707 to 130.64810, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 6/100\n",
        "100/100 [==============================] - 90s 897ms/step - loss: 79.9279 - mean_squared_error: 79.6348 - val_loss: 51.6152 - val_mean_squared_error: 146.6444\n",
        "\n",
        "Epoch 00006: val_mean_squared_error did not improve from 130.64810\n",
        "Epoch 7/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 80.3534 - mean_squared_error: 80.3534 - val_loss: 122.4674 - val_mean_squared_error: 162.3162\n",
        "\n",
        "Epoch 00007: val_mean_squared_error did not improve from 130.64810\n",
        "Epoch 8/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 87.9992 - mean_squared_error: 88.1383 - val_loss: 137.2898 - val_mean_squared_error: 151.3750\n",
        "\n",
        "Epoch 00008: val_mean_squared_error did not improve from 130.64810\n",
        "Epoch 9/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 87.8130 - mean_squared_error: 87.8130 - val_loss: 85.2790 - val_mean_squared_error: 129.7551\n",
        "\n",
        "Epoch 00009: val_mean_squared_error improved from 130.64810 to 129.75510, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 10/100\n",
        "100/100 [==============================] - 90s 897ms/step - loss: 83.5959 - mean_squared_error: 83.5959 - val_loss: 145.7229 - val_mean_squared_error: 146.7649\n",
        "\n",
        "Epoch 00010: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 11/100\n",
        "100/100 [==============================] - 85s 850ms/step - loss: 89.0400 - mean_squared_error: 88.7290 - val_loss: 146.1507 - val_mean_squared_error: 146.6706\n",
        "\n",
        "Epoch 00011: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 12/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 83.8278 - mean_squared_error: 83.7742 - val_loss: 98.3254 - val_mean_squared_error: 156.6070\n",
        "\n",
        "Epoch 00012: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 13/100\n",
        "100/100 [==============================] - 90s 900ms/step - loss: 81.7200 - mean_squared_error: 81.7200 - val_loss: 118.2779 - val_mean_squared_error: 144.4838\n",
        "\n",
        "Epoch 00013: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 14/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 82.8513 - mean_squared_error: 83.0284 - val_loss: 119.4236 - val_mean_squared_error: 130.3614\n",
        "\n",
        "Epoch 00014: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 15/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 83.8128 - mean_squared_error: 83.8128 - val_loss: 135.4687 - val_mean_squared_error: 142.8367\n",
        "\n",
        "Epoch 00015: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 16/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 78.8642 - mean_squared_error: 78.8283 - val_loss: 125.2538 - val_mean_squared_error: 137.9031\n",
        "\n",
        "Epoch 00016: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 17/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 84.5025 - mean_squared_error: 84.4535 - val_loss: 190.5390 - val_mean_squared_error: 136.4127\n",
        "\n",
        "Epoch 00017: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 18/100\n",
        "100/100 [==============================] - 86s 855ms/step - loss: 81.8873 - mean_squared_error: 81.7696 - val_loss: 126.8441 - val_mean_squared_error: 145.3955\n",
        "\n",
        "Epoch 00018: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 19/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 83.7469 - mean_squared_error: 83.7469 - val_loss: 168.9765 - val_mean_squared_error: 133.5743\n",
        "\n",
        "Epoch 00019: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 20/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 78.8184 - mean_squared_error: 79.0087 - val_loss: 112.4094 - val_mean_squared_error: 131.2357\n",
        "\n",
        "Epoch 00020: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 21/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 81.2634 - mean_squared_error: 81.2634 - val_loss: 145.5037 - val_mean_squared_error: 132.2620\n",
        "\n",
        "Epoch 00021: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 22/100\n",
        "100/100 [==============================] - 85s 845ms/step - loss: 80.7318 - mean_squared_error: 80.7062 - val_loss: 139.8304 - val_mean_squared_error: 139.8824\n",
        "\n",
        "Epoch 00022: val_mean_squared_error did not improve from 129.75510\n",
        "Epoch 23/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 78.4502 - mean_squared_error: 78.5317 - val_loss: 96.3247 - val_mean_squared_error: 124.3349\n",
        "\n",
        "Epoch 00023: val_mean_squared_error improved from 129.75510 to 124.33488, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 24/100\n",
        "100/100 [==============================] - 88s 883ms/step - loss: 76.7556 - mean_squared_error: 76.7556 - val_loss: 110.6103 - val_mean_squared_error: 141.5789\n",
        "\n",
        "Epoch 00024: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 25/100\n",
        "100/100 [==============================] - 88s 878ms/step - loss: 82.7226 - mean_squared_error: 82.7226 - val_loss: 141.3526 - val_mean_squared_error: 150.9841\n",
        "\n",
        "Epoch 00025: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 26/100\n",
        "100/100 [==============================] - 85s 849ms/step - loss: 79.5579 - mean_squared_error: 79.6176 - val_loss: 83.7892 - val_mean_squared_error: 138.8925\n",
        "\n",
        "Epoch 00026: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 27/100\n",
        "100/100 [==============================] - 85s 847ms/step - loss: 78.2406 - mean_squared_error: 78.2152 - val_loss: 143.8715 - val_mean_squared_error: 128.7074\n",
        "\n",
        "Epoch 00027: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 28/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 80.7520 - mean_squared_error: 80.7520 - val_loss: 119.7866 - val_mean_squared_error: 151.3671\n",
        "\n",
        "Epoch 00028: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 29/100\n",
        "100/100 [==============================] - 84s 845ms/step - loss: 81.2101 - mean_squared_error: 81.2307 - val_loss: 125.4790 - val_mean_squared_error: 141.7880\n",
        "\n",
        "Epoch 00029: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 30/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 84.0264 - mean_squared_error: 84.0264 - val_loss: 49.4095 - val_mean_squared_error: 157.0199\n",
        "\n",
        "Epoch 00030: val_mean_squared_error did not improve from 124.33488\n",
        "Epoch 31/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 78.6769 - mean_squared_error: 78.7334 - val_loss: 131.4120 - val_mean_squared_error: 120.2594\n",
        "\n",
        "Epoch 00031: val_mean_squared_error improved from 124.33488 to 120.25942, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 32/100\n",
        "100/100 [==============================] - 92s 917ms/step - loss: 77.5758 - mean_squared_error: 77.5758 - val_loss: 128.4001 - val_mean_squared_error: 143.1685\n",
        "\n",
        "Epoch 00032: val_mean_squared_error did not improve from 120.25942\n",
        "Epoch 33/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 77.3566 - mean_squared_error: 77.3536 - val_loss: 128.8928 - val_mean_squared_error: 124.0751\n",
        "\n",
        "Epoch 00033: val_mean_squared_error did not improve from 120.25942\n",
        "Epoch 34/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 78.6146 - mean_squared_error: 78.3652 - val_loss: 146.7915 - val_mean_squared_error: 118.2027\n",
        "\n",
        "Epoch 00034: val_mean_squared_error improved from 120.25942 to 118.20266, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 35/100\n",
        "100/100 [==============================] - 88s 884ms/step - loss: 77.4003 - mean_squared_error: 76.8454 - val_loss: 248.9651 - val_mean_squared_error: 158.8719\n",
        "\n",
        "Epoch 00035: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 36/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 75.0344 - mean_squared_error: 75.0344 - val_loss: 88.4242 - val_mean_squared_error: 127.2878\n",
        "\n",
        "Epoch 00036: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 37/100\n",
        "100/100 [==============================] - 88s 885ms/step - loss: 79.1578 - mean_squared_error: 78.9351 - val_loss: 115.3749 - val_mean_squared_error: 129.2894\n",
        "\n",
        "Epoch 00037: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 38/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 75.5747 - mean_squared_error: 75.5747 - val_loss: 156.9515 - val_mean_squared_error: 148.8403\n",
        "\n",
        "Epoch 00038: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 39/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 76.5336 - mean_squared_error: 76.5335 - val_loss: 155.1822 - val_mean_squared_error: 128.7759\n",
        "\n",
        "Epoch 00039: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 40/100\n",
        "100/100 [==============================] - 85s 849ms/step - loss: 78.4803 - mean_squared_error: 78.7303 - val_loss: 97.0133 - val_mean_squared_error: 129.5398\n",
        "\n",
        "Epoch 00040: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 41/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 77.6899 - mean_squared_error: 77.6899 - val_loss: 102.8747 - val_mean_squared_error: 120.1187\n",
        "\n",
        "Epoch 00041: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 42/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 78.2169 - mean_squared_error: 78.2169 - val_loss: 55.1866 - val_mean_squared_error: 129.4085\n",
        "\n",
        "Epoch 00042: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 43/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 82.3342 - mean_squared_error: 82.1497 - val_loss: 108.6703 - val_mean_squared_error: 132.0959\n",
        "\n",
        "Epoch 00043: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 44/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 80.9944 - mean_squared_error: 80.9944 - val_loss: 92.3176 - val_mean_squared_error: 139.2290\n",
        "\n",
        "Epoch 00044: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 45/100\n",
        "100/100 [==============================] - 87s 867ms/step - loss: 76.1511 - mean_squared_error: 76.2342 - val_loss: 159.0683 - val_mean_squared_error: 143.0112\n",
        "\n",
        "Epoch 00045: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 46/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 74.8550 - mean_squared_error: 75.0075 - val_loss: 93.9144 - val_mean_squared_error: 132.9788\n",
        "\n",
        "Epoch 00046: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 47/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 81.4724 - mean_squared_error: 81.4893 - val_loss: 135.5298 - val_mean_squared_error: 144.5894\n",
        "\n",
        "Epoch 00047: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 48/100\n",
        "100/100 [==============================] - 87s 868ms/step - loss: 79.3709 - mean_squared_error: 79.3709 - val_loss: 162.2007 - val_mean_squared_error: 128.0482\n",
        "\n",
        "Epoch 00048: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 49/100\n",
        "100/100 [==============================] - 88s 880ms/step - loss: 73.2362 - mean_squared_error: 73.4457 - val_loss: 159.7460 - val_mean_squared_error: 148.3568\n",
        "\n",
        "Epoch 00049: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 50/100\n",
        "100/100 [==============================] - 87s 868ms/step - loss: 74.9660 - mean_squared_error: 74.9660 - val_loss: 138.9523 - val_mean_squared_error: 136.3526\n",
        "\n",
        "Epoch 00050: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 51/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 71.9543 - mean_squared_error: 71.9844 - val_loss: 176.0027 - val_mean_squared_error: 126.8025\n",
        "\n",
        "Epoch 00051: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 52/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 73.0283 - mean_squared_error: 73.0283 - val_loss: 105.0471 - val_mean_squared_error: 128.6200\n",
        "\n",
        "Epoch 00052: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 53/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 75.5720 - mean_squared_error: 75.5567 - val_loss: 93.6776 - val_mean_squared_error: 128.7806\n",
        "\n",
        "Epoch 00053: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 54/100\n",
        "100/100 [==============================] - 84s 843ms/step - loss: 79.3783 - mean_squared_error: 79.4533 - val_loss: 68.3504 - val_mean_squared_error: 122.9732\n",
        "\n",
        "Epoch 00054: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 55/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 76.4321 - mean_squared_error: 76.4321 - val_loss: 192.5692 - val_mean_squared_error: 140.7068\n",
        "\n",
        "Epoch 00055: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 56/100\n",
        "100/100 [==============================] - 89s 892ms/step - loss: 73.6769 - mean_squared_error: 73.5808 - val_loss: 162.8800 - val_mean_squared_error: 144.0710\n",
        "\n",
        "Epoch 00056: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 57/100\n",
        "100/100 [==============================] - 86s 855ms/step - loss: 76.3357 - mean_squared_error: 76.3357 - val_loss: 298.9951 - val_mean_squared_error: 146.3663\n",
        "\n",
        "Epoch 00057: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 58/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 71.9115 - mean_squared_error: 71.8447 - val_loss: 173.1465 - val_mean_squared_error: 141.5875\n",
        "\n",
        "Epoch 00058: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 59/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 77.5351 - mean_squared_error: 77.5351 - val_loss: 131.8470 - val_mean_squared_error: 153.9881\n",
        "\n",
        "Epoch 00059: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 60/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 76.9444 - mean_squared_error: 76.9444 - val_loss: 167.8748 - val_mean_squared_error: 131.9343\n",
        "\n",
        "Epoch 00060: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 61/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 73.9766 - mean_squared_error: 73.7787 - val_loss: 136.2417 - val_mean_squared_error: 129.0527\n",
        "\n",
        "Epoch 00061: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 62/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 70.8863 - mean_squared_error: 70.8863 - val_loss: 113.8298 - val_mean_squared_error: 130.0677\n",
        "\n",
        "Epoch 00062: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 63/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 72.7542 - mean_squared_error: 72.7542 - val_loss: 179.2425 - val_mean_squared_error: 141.2728\n",
        "\n",
        "Epoch 00063: val_mean_squared_error did not improve from 118.20266\n",
        "Epoch 64/100\n",
        "100/100 [==============================] - 84s 845ms/step - loss: 71.2743 - mean_squared_error: 71.2449 - val_loss: 87.0836 - val_mean_squared_error: 115.9856\n",
        "\n",
        "Epoch 00064: val_mean_squared_error improved from 118.20266 to 115.98560, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 65/100\n",
        "100/100 [==============================] - 89s 886ms/step - loss: 72.2340 - mean_squared_error: 72.2340 - val_loss: 165.2793 - val_mean_squared_error: 131.8042\n",
        "\n",
        "Epoch 00065: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 66/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 74.0461 - mean_squared_error: 74.1093 - val_loss: 207.1332 - val_mean_squared_error: 137.2825\n",
        "\n",
        "Epoch 00066: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 67/100\n",
        "100/100 [==============================] - 85s 847ms/step - loss: 71.5185 - mean_squared_error: 71.6791 - val_loss: 195.9727 - val_mean_squared_error: 143.4037\n",
        "\n",
        "Epoch 00067: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 68/100\n",
        "100/100 [==============================] - 88s 877ms/step - loss: 71.9998 - mean_squared_error: 71.9997 - val_loss: 235.9081 - val_mean_squared_error: 164.8851\n",
        "\n",
        "Epoch 00068: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 69/100\n",
        "100/100 [==============================] - 85s 846ms/step - loss: 73.1378 - mean_squared_error: 73.3009 - val_loss: 153.6225 - val_mean_squared_error: 149.2819\n",
        "\n",
        "Epoch 00069: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 70/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 73.0571 - mean_squared_error: 73.0571 - val_loss: 124.1112 - val_mean_squared_error: 142.7087\n",
        "\n",
        "Epoch 00070: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 71/100\n",
        "100/100 [==============================] - 85s 847ms/step - loss: 75.4016 - mean_squared_error: 75.4722 - val_loss: 158.8396 - val_mean_squared_error: 142.4804\n",
        "\n",
        "Epoch 00071: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 72/100\n",
        "100/100 [==============================] - 85s 848ms/step - loss: 74.5967 - mean_squared_error: 74.2894 - val_loss: 50.2020 - val_mean_squared_error: 125.5096\n",
        "\n",
        "Epoch 00072: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 73/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 72.8817 - mean_squared_error: 72.8817 - val_loss: 138.0039 - val_mean_squared_error: 134.6296\n",
        "\n",
        "Epoch 00073: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 74/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 75.1302 - mean_squared_error: 75.3163 - val_loss: 260.3552 - val_mean_squared_error: 152.0382\n",
        "\n",
        "Epoch 00074: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 75/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 72.4904 - mean_squared_error: 72.4904 - val_loss: 136.6190 - val_mean_squared_error: 122.5949\n",
        "\n",
        "Epoch 00075: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 76/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 71.7714 - mean_squared_error: 71.7628 - val_loss: 147.6069 - val_mean_squared_error: 134.6798\n",
        "\n",
        "Epoch 00076: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 77/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 72.1438 - mean_squared_error: 72.0759 - val_loss: 122.2744 - val_mean_squared_error: 166.5933\n",
        "\n",
        "Epoch 00077: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 78/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 72.7289 - mean_squared_error: 72.7482 - val_loss: 348.6606 - val_mean_squared_error: 125.9873\n",
        "\n",
        "Epoch 00078: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 79/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 73.6336 - mean_squared_error: 73.6336 - val_loss: 160.6543 - val_mean_squared_error: 148.5906\n",
        "\n",
        "Epoch 00079: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 80/100\n",
        "100/100 [==============================] - 88s 876ms/step - loss: 70.7092 - mean_squared_error: 70.7092 - val_loss: 137.2147 - val_mean_squared_error: 128.0918\n",
        "\n",
        "Epoch 00080: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 81/100\n",
        "100/100 [==============================] - 85s 852ms/step - loss: 68.9823 - mean_squared_error: 69.0461 - val_loss: 106.6812 - val_mean_squared_error: 131.5383\n",
        "\n",
        "Epoch 00081: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 82/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 70.8033 - mean_squared_error: 70.8033 - val_loss: 134.8899 - val_mean_squared_error: 129.3482\n",
        "\n",
        "Epoch 00082: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 83/100\n",
        "100/100 [==============================] - 85s 846ms/step - loss: 72.3811 - mean_squared_error: 71.8932 - val_loss: 157.8451 - val_mean_squared_error: 132.2200\n",
        "\n",
        "Epoch 00083: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 84/100\n",
        "100/100 [==============================] - 86s 856ms/step - loss: 70.6128 - mean_squared_error: 70.6128 - val_loss: 17.9824 - val_mean_squared_error: 131.5254\n",
        "\n",
        "Epoch 00084: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 85/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 74.4293 - mean_squared_error: 74.4293 - val_loss: 123.7780 - val_mean_squared_error: 136.0406\n",
        "\n",
        "Epoch 00085: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 86/100\n",
        "100/100 [==============================] - 85s 853ms/step - loss: 69.5959 - mean_squared_error: 69.6773 - val_loss: 99.9544 - val_mean_squared_error: 142.3683\n",
        "\n",
        "Epoch 00086: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 87/100\n",
        "100/100 [==============================] - 85s 855ms/step - loss: 69.9998 - mean_squared_error: 70.2519 - val_loss: 95.6782 - val_mean_squared_error: 125.0951\n",
        "\n",
        "Epoch 00087: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 88/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 71.0011 - mean_squared_error: 71.0011 - val_loss: 94.0424 - val_mean_squared_error: 129.4142\n",
        "\n",
        "Epoch 00088: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 89/100\n",
        "100/100 [==============================] - 85s 850ms/step - loss: 73.3638 - mean_squared_error: 73.0073 - val_loss: 132.0457 - val_mean_squared_error: 137.6255\n",
        "\n",
        "Epoch 00089: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 90/100\n",
        "100/100 [==============================] - 85s 848ms/step - loss: 70.6856 - mean_squared_error: 70.6856 - val_loss: 322.3716 - val_mean_squared_error: 135.3705\n",
        "\n",
        "Epoch 00090: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 91/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 69.6805 - mean_squared_error: 69.7435 - val_loss: 170.8643 - val_mean_squared_error: 153.4463\n",
        "\n",
        "Epoch 00091: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 92/100\n",
        "100/100 [==============================] - 88s 880ms/step - loss: 72.8876 - mean_squared_error: 72.8876 - val_loss: 133.7745 - val_mean_squared_error: 133.5135\n",
        "\n",
        "Epoch 00092: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 93/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 66.6322 - mean_squared_error: 66.6285 - val_loss: 104.3438 - val_mean_squared_error: 127.7034\n",
        "\n",
        "Epoch 00093: val_mean_squared_error did not improve from 115.98560\n",
        "Epoch 94/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 70.2314 - mean_squared_error: 70.2314 - val_loss: 115.6604 - val_mean_squared_error: 115.3278\n",
        "\n",
        "Epoch 00094: val_mean_squared_error improved from 115.98560 to 115.32784, saving model to douglas_rodando_regressao_2.h5\n",
        "Epoch 95/100\n",
        "100/100 [==============================] - 91s 910ms/step - loss: 71.7500 - mean_squared_error: 71.9519 - val_loss: 105.5259 - val_mean_squared_error: 135.1566\n",
        "\n",
        "Epoch 00095: val_mean_squared_error did not improve from 115.32784\n",
        "Epoch 96/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 73.6925 - mean_squared_error: 73.8219 - val_loss: 219.0654 - val_mean_squared_error: 129.5034\n",
        "\n",
        "Epoch 00096: val_mean_squared_error did not improve from 115.32784\n",
        "Epoch 97/100\n",
        "100/100 [==============================] - 87s 872ms/step - loss: 72.0022 - mean_squared_error: 72.0022 - val_loss: 160.7458 - val_mean_squared_error: 125.0527\n",
        "\n",
        "Epoch 00097: val_mean_squared_error did not improve from 115.32784\n",
        "Epoch 98/100\n",
        "100/100 [==============================] - 87s 867ms/step - loss: 68.0751 - mean_squared_error: 68.1108 - val_loss: 178.3427 - val_mean_squared_error: 132.7471\n",
        "\n",
        "Epoch 00098: val_mean_squared_error did not improve from 115.32784\n",
        "Epoch 99/100\n",
        "100/100 [==============================] - 91s 906ms/step - loss: 67.1316 - mean_squared_error: 67.1644 - val_loss: 213.0440 - val_mean_squared_error: 120.5083\n",
        "\n",
        "Epoch 00099: val_mean_squared_error did not improve from 115.32784\n",
        "Epoch 100/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 70.1755 - mean_squared_error: 70.1755 - val_loss: 146.8397 - val_mean_squared_error: 147.7193\n",
        "\n",
        "Epoch 00100: val_mean_squared_error did not improve from 115.32784"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skKocE3aQK8"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"douglas_rodando_regressao_3.h5\",\n",
        "                             monitor='val_mean_squared_error',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto',\n",
        "                             period=1)\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "modelrecuperado= load_model('douglas_rodando_regressao_2.h5')\n",
        "\n",
        "for layer in modelrecuperado.layers[:18]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "hist = modelrecuperado.fit_generator(steps_per_epoch=100,\n",
        "                           generator=traindata,\n",
        "                           validation_data= valdata,\n",
        "                           validation_steps=100,\n",
        "                           epochs=100,\n",
        "                           callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooI0-SO_q2rT"
      },
      "source": [
        "Epoch 1/100\n",
        "100/100 [==============================] - 93s 928ms/step - loss: 67.8683 - mean_squared_error: 67.6800 - val_loss: 258.4449 - val_mean_squared_error: 159.3481\n",
        "\n",
        "Epoch 00001: val_mean_squared_error improved from inf to 159.34808, saving model to douglas_rodando_regressao_3.h5\n",
        "Epoch 2/100\n",
        "100/100 [==============================] - 90s 902ms/step - loss: 71.8530 - mean_squared_error: 71.8530 - val_loss: 118.6799 - val_mean_squared_error: 132.9466\n",
        "\n",
        "Epoch 00002: val_mean_squared_error improved from 159.34808 to 132.94656, saving model to douglas_rodando_regressao_3.h5\n",
        "Epoch 3/100\n",
        "100/100 [==============================] - 93s 929ms/step - loss: 71.7101 - mean_squared_error: 71.6070 - val_loss: 156.2189 - val_mean_squared_error: 134.0632\n",
        "\n",
        "Epoch 00003: val_mean_squared_error did not improve from 132.94656\n",
        "Epoch 4/100\n",
        "100/100 [==============================] - 87s 867ms/step - loss: 72.9600 - mean_squared_error: 72.9600 - val_loss: 90.0762 - val_mean_squared_error: 121.5936\n",
        "\n",
        "Epoch 00004: val_mean_squared_error improved from 132.94656 to 121.59360, saving model to douglas_rodando_regressao_3.h5\n",
        "Epoch 5/100\n",
        "100/100 [==============================] - 92s 919ms/step - loss: 69.9942 - mean_squared_error: 69.6215 - val_loss: 179.4611 - val_mean_squared_error: 118.3235\n",
        "\n",
        "Epoch 00005: val_mean_squared_error improved from 121.59360 to 118.32346, saving model to douglas_rodando_regressao_3.h5\n",
        "Epoch 6/100\n",
        "100/100 [==============================] - 91s 912ms/step - loss: 67.7170 - mean_squared_error: 67.5549 - val_loss: 27.9477 - val_mean_squared_error: 124.2177\n",
        "\n",
        "Epoch 00006: val_mean_squared_error did not improve from 118.32346\n",
        "Epoch 7/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 71.8502 - mean_squared_error: 71.8503 - val_loss: 130.6656 - val_mean_squared_error: 136.2346\n",
        "\n",
        "Epoch 00007: val_mean_squared_error did not improve from 118.32346\n",
        "Epoch 8/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 68.2033 - mean_squared_error: 68.3580 - val_loss: 124.7835 - val_mean_squared_error: 133.5268\n",
        "\n",
        "Epoch 00008: val_mean_squared_error did not improve from 118.32346\n",
        "Epoch 9/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 72.0948 - mean_squared_error: 72.0948 - val_loss: 173.1877 - val_mean_squared_error: 131.3098\n",
        "\n",
        "Epoch 00009: val_mean_squared_error did not improve from 118.32346\n",
        "Epoch 10/100\n",
        "100/100 [==============================] - 85s 846ms/step - loss: 71.1065 - mean_squared_error: 71.1141 - val_loss: 206.3829 - val_mean_squared_error: 154.2188\n",
        "\n",
        "Epoch 00010: val_mean_squared_error did not improve from 118.32346\n",
        "Epoch 11/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 68.1354 - mean_squared_error: 68.1354 - val_loss: 170.3312 - val_mean_squared_error: 110.3482\n",
        "\n",
        "Epoch 00011: val_mean_squared_error improved from 118.32346 to 110.34821, saving model to douglas_rodando_regressao_3.h5\n",
        "Epoch 12/100\n",
        "100/100 [==============================] - 89s 888ms/step - loss: 67.5135 - mean_squared_error: 67.5135 - val_loss: 86.5836 - val_mean_squared_error: 121.6905\n",
        "\n",
        "Epoch 00012: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 13/100\n",
        "100/100 [==============================] - 88s 885ms/step - loss: 73.4151 - mean_squared_error: 73.5298 - val_loss: 85.4614 - val_mean_squared_error: 130.5551\n",
        "\n",
        "Epoch 00013: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 14/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 68.1864 - mean_squared_error: 68.1863 - val_loss: 86.2977 - val_mean_squared_error: 114.7630\n",
        "\n",
        "Epoch 00014: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 15/100\n",
        "100/100 [==============================] - 85s 854ms/step - loss: 67.7243 - mean_squared_error: 67.7243 - val_loss: 107.7846 - val_mean_squared_error: 125.5709\n",
        "\n",
        "Epoch 00015: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 16/100\n",
        "100/100 [==============================] - 84s 844ms/step - loss: 67.6966 - mean_squared_error: 67.7037 - val_loss: 99.5461 - val_mean_squared_error: 131.5904\n",
        "\n",
        "Epoch 00016: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 17/100\n",
        "100/100 [==============================] - 85s 848ms/step - loss: 69.5033 - mean_squared_error: 69.5564 - val_loss: 129.5430 - val_mean_squared_error: 142.6366\n",
        "\n",
        "Epoch 00017: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 18/100\n",
        "100/100 [==============================] - 85s 850ms/step - loss: 69.3465 - mean_squared_error: 69.2968 - val_loss: 108.9827 - val_mean_squared_error: 121.6076\n",
        "\n",
        "Epoch 00018: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 19/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 69.3215 - mean_squared_error: 69.3215 - val_loss: 143.8165 - val_mean_squared_error: 119.0319\n",
        "\n",
        "Epoch 00019: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 20/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 71.2909 - mean_squared_error: 71.2909 - val_loss: 127.3136 - val_mean_squared_error: 134.8245\n",
        "\n",
        "Epoch 00020: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 21/100\n",
        "100/100 [==============================] - 85s 851ms/step - loss: 68.6761 - mean_squared_error: 68.6752 - val_loss: 116.1241 - val_mean_squared_error: 128.8852\n",
        "\n",
        "Epoch 00021: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 22/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 65.6298 - mean_squared_error: 65.5064 - val_loss: 94.4723 - val_mean_squared_error: 131.9300\n",
        "\n",
        "Epoch 00022: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 23/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 64.6185 - mean_squared_error: 64.6185 - val_loss: 147.4521 - val_mean_squared_error: 124.9022\n",
        "\n",
        "Epoch 00023: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 24/100\n",
        "100/100 [==============================] - 86s 855ms/step - loss: 66.4774 - mean_squared_error: 66.5585 - val_loss: 174.4065 - val_mean_squared_error: 139.3069\n",
        "\n",
        "Epoch 00024: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 25/100\n",
        "100/100 [==============================] - 89s 886ms/step - loss: 70.3770 - mean_squared_error: 70.3724 - val_loss: 149.0513 - val_mean_squared_error: 127.1688\n",
        "\n",
        "Epoch 00025: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 26/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 69.7710 - mean_squared_error: 69.7710 - val_loss: 146.5345 - val_mean_squared_error: 140.4519\n",
        "\n",
        "Epoch 00026: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 27/100\n",
        "100/100 [==============================] - 84s 843ms/step - loss: 68.0375 - mean_squared_error: 67.9003 - val_loss: 169.9945 - val_mean_squared_error: 124.6702\n",
        "\n",
        "Epoch 00027: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 28/100\n",
        "100/100 [==============================] - 85s 848ms/step - loss: 67.4592 - mean_squared_error: 67.4592 - val_loss: 163.2820 - val_mean_squared_error: 128.8938\n",
        "\n",
        "Epoch 00028: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 29/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 68.3707 - mean_squared_error: 68.3903 - val_loss: 105.8075 - val_mean_squared_error: 119.8313\n",
        "\n",
        "Epoch 00029: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 30/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 66.0839 - mean_squared_error: 66.0645 - val_loss: 86.4725 - val_mean_squared_error: 132.5179\n",
        "\n",
        "Epoch 00030: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 31/100\n",
        "100/100 [==============================] - 87s 870ms/step - loss: 69.8448 - mean_squared_error: 69.8448 - val_loss: 160.9451 - val_mean_squared_error: 124.6576\n",
        "\n",
        "Epoch 00031: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 32/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 67.6943 - mean_squared_error: 67.6575 - val_loss: 178.1855 - val_mean_squared_error: 123.8929\n",
        "\n",
        "Epoch 00032: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 33/100\n",
        "100/100 [==============================] - 87s 872ms/step - loss: 68.7285 - mean_squared_error: 68.7285 - val_loss: 150.9595 - val_mean_squared_error: 130.5757\n",
        "\n",
        "Epoch 00033: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 34/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 65.9429 - mean_squared_error: 65.9048 - val_loss: 155.9475 - val_mean_squared_error: 127.9386\n",
        "\n",
        "Epoch 00034: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 35/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 64.4935 - mean_squared_error: 64.5460 - val_loss: 144.4529 - val_mean_squared_error: 127.1026\n",
        "\n",
        "Epoch 00035: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 36/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 68.9722 - mean_squared_error: 68.9722 - val_loss: 82.7339 - val_mean_squared_error: 129.5826\n",
        "\n",
        "Epoch 00036: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 37/100\n",
        "100/100 [==============================] - 89s 892ms/step - loss: 71.3556 - mean_squared_error: 71.3556 - val_loss: 131.3629 - val_mean_squared_error: 125.1813\n",
        "\n",
        "Epoch 00037: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 38/100\n",
        "100/100 [==============================] - 87s 869ms/step - loss: 64.7491 - mean_squared_error: 64.9172 - val_loss: 134.0328 - val_mean_squared_error: 127.0793\n",
        "\n",
        "Epoch 00038: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 39/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 66.6334 - mean_squared_error: 66.4179 - val_loss: 109.6064 - val_mean_squared_error: 124.2337\n",
        "\n",
        "Epoch 00039: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 40/100\n",
        "100/100 [==============================] - 87s 868ms/step - loss: 68.6845 - mean_squared_error: 68.6845 - val_loss: 191.8341 - val_mean_squared_error: 122.8701\n",
        "\n",
        "Epoch 00040: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 41/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 65.8777 - mean_squared_error: 66.0028 - val_loss: 123.2636 - val_mean_squared_error: 115.9077\n",
        "\n",
        "Epoch 00041: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 42/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 68.8861 - mean_squared_error: 68.8861 - val_loss: 33.9735 - val_mean_squared_error: 121.6826\n",
        "\n",
        "Epoch 00042: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 43/100\n",
        "100/100 [==============================] - 87s 870ms/step - loss: 67.6034 - mean_squared_error: 67.5745 - val_loss: 131.3232 - val_mean_squared_error: 124.1447\n",
        "\n",
        "Epoch 00043: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 44/100\n",
        "100/100 [==============================] - 87s 873ms/step - loss: 67.6468 - mean_squared_error: 67.5628 - val_loss: 142.6400 - val_mean_squared_error: 131.7350\n",
        "\n",
        "Epoch 00044: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 45/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 66.1955 - mean_squared_error: 66.1955 - val_loss: 142.5582 - val_mean_squared_error: 116.2697\n",
        "\n",
        "Epoch 00045: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 46/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 66.0773 - mean_squared_error: 66.1677 - val_loss: 84.6101 - val_mean_squared_error: 135.5958\n",
        "\n",
        "Epoch 00046: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 47/100\n",
        "100/100 [==============================] - 87s 868ms/step - loss: 66.9945 - mean_squared_error: 66.9945 - val_loss: 144.5728 - val_mean_squared_error: 130.6205\n",
        "\n",
        "Epoch 00047: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 48/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 69.4648 - mean_squared_error: 69.5678 - val_loss: 174.4235 - val_mean_squared_error: 121.3953\n",
        "\n",
        "Epoch 00048: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 49/100\n",
        "100/100 [==============================] - 88s 878ms/step - loss: 63.2756 - mean_squared_error: 63.2046 - val_loss: 81.2858 - val_mean_squared_error: 116.4649\n",
        "\n",
        "Epoch 00049: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 50/100\n",
        "100/100 [==============================] - 87s 872ms/step - loss: 67.0625 - mean_squared_error: 67.0625 - val_loss: 79.9684 - val_mean_squared_error: 113.9635\n",
        "\n",
        "Epoch 00050: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 51/100\n",
        "100/100 [==============================] - 87s 869ms/step - loss: 68.2062 - mean_squared_error: 68.2833 - val_loss: 132.1589 - val_mean_squared_error: 120.5441\n",
        "\n",
        "Epoch 00051: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 52/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 66.0425 - mean_squared_error: 66.0425 - val_loss: 125.6931 - val_mean_squared_error: 122.4667\n",
        "\n",
        "Epoch 00052: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 53/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 68.0311 - mean_squared_error: 67.8501 - val_loss: 117.6083 - val_mean_squared_error: 126.5801\n",
        "\n",
        "Epoch 00053: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 54/100\n",
        "100/100 [==============================] - 86s 857ms/step - loss: 63.4630 - mean_squared_error: 63.5051 - val_loss: 101.6279 - val_mean_squared_error: 129.8763\n",
        "\n",
        "Epoch 00054: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 55/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 66.7392 - mean_squared_error: 66.7392 - val_loss: 113.9726 - val_mean_squared_error: 118.4533\n",
        "\n",
        "Epoch 00055: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 56/100\n",
        "100/100 [==============================] - 90s 898ms/step - loss: 64.7102 - mean_squared_error: 64.6816 - val_loss: 106.0058 - val_mean_squared_error: 127.1018\n",
        "\n",
        "Epoch 00056: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 57/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 64.9699 - mean_squared_error: 64.9699 - val_loss: 112.1790 - val_mean_squared_error: 129.3004\n",
        "\n",
        "Epoch 00057: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 58/100\n",
        "100/100 [==============================] - 87s 873ms/step - loss: 65.1179 - mean_squared_error: 65.1179 - val_loss: 91.0550 - val_mean_squared_error: 115.1429\n",
        "\n",
        "Epoch 00058: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 59/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 66.4286 - mean_squared_error: 66.5039 - val_loss: 116.4428 - val_mean_squared_error: 112.1915\n",
        "\n",
        "Epoch 00059: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 60/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 64.5014 - mean_squared_error: 64.6349 - val_loss: 75.5232 - val_mean_squared_error: 133.8186\n",
        "\n",
        "Epoch 00060: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 61/100\n",
        "100/100 [==============================] - 87s 872ms/step - loss: 63.0875 - mean_squared_error: 63.0875 - val_loss: 108.4936 - val_mean_squared_error: 139.7083\n",
        "\n",
        "Epoch 00061: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 62/100\n",
        "100/100 [==============================] - 87s 869ms/step - loss: 67.4497 - mean_squared_error: 67.2743 - val_loss: 106.7790 - val_mean_squared_error: 142.1365\n",
        "\n",
        "Epoch 00062: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 63/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 66.9904 - mean_squared_error: 67.0294 - val_loss: 129.1764 - val_mean_squared_error: 138.5579\n",
        "\n",
        "Epoch 00063: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 64/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 67.6451 - mean_squared_error: 67.5641 - val_loss: 105.8048 - val_mean_squared_error: 128.2950\n",
        "\n",
        "Epoch 00064: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 65/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 62.9419 - mean_squared_error: 62.9419 - val_loss: 114.2240 - val_mean_squared_error: 120.1678\n",
        "\n",
        "Epoch 00065: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 66/100\n",
        "100/100 [==============================] - 86s 859ms/step - loss: 66.0319 - mean_squared_error: 66.0319 - val_loss: 14.4795 - val_mean_squared_error: 119.5230\n",
        "\n",
        "Epoch 00066: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 67/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 63.9550 - mean_squared_error: 63.9550 - val_loss: 117.6731 - val_mean_squared_error: 131.5426\n",
        "\n",
        "Epoch 00067: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 68/100\n",
        "100/100 [==============================] - 89s 894ms/step - loss: 65.4972 - mean_squared_error: 65.4623 - val_loss: 90.2139 - val_mean_squared_error: 126.2941\n",
        "\n",
        "Epoch 00068: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 69/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 63.2739 - mean_squared_error: 63.1406 - val_loss: 141.6268 - val_mean_squared_error: 116.4945\n",
        "\n",
        "Epoch 00069: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 70/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 65.0117 - mean_squared_error: 65.0117 - val_loss: 179.1170 - val_mean_squared_error: 144.7862\n",
        "\n",
        "Epoch 00070: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 71/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 64.5600 - mean_squared_error: 64.2359 - val_loss: 119.5647 - val_mean_squared_error: 122.8707\n",
        "\n",
        "Epoch 00071: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 72/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 64.0134 - mean_squared_error: 64.0134 - val_loss: 94.7960 - val_mean_squared_error: 140.8474\n",
        "\n",
        "Epoch 00072: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 73/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 63.8743 - mean_squared_error: 63.8380 - val_loss: 122.2454 - val_mean_squared_error: 132.1671\n",
        "\n",
        "Epoch 00073: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 74/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 66.3878 - mean_squared_error: 66.3878 - val_loss: 119.3668 - val_mean_squared_error: 134.5359\n",
        "\n",
        "Epoch 00074: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 75/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 64.1395 - mean_squared_error: 64.3618 - val_loss: 155.0909 - val_mean_squared_error: 118.9643\n",
        "\n",
        "Epoch 00075: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 76/100\n",
        "100/100 [==============================] - 87s 869ms/step - loss: 64.0612 - mean_squared_error: 64.0612 - val_loss: 110.4148 - val_mean_squared_error: 115.9951\n",
        "\n",
        "Epoch 00076: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 77/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 65.8341 - mean_squared_error: 65.8341 - val_loss: 125.5526 - val_mean_squared_error: 124.1072\n",
        "\n",
        "Epoch 00077: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 78/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 63.6649 - mean_squared_error: 63.6997 - val_loss: 27.1352 - val_mean_squared_error: 128.3027\n",
        "\n",
        "Epoch 00078: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 79/100\n",
        "100/100 [==============================] - 87s 868ms/step - loss: 66.4551 - mean_squared_error: 66.4551 - val_loss: 163.1993 - val_mean_squared_error: 130.1967\n",
        "\n",
        "Epoch 00079: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 80/100\n",
        "100/100 [==============================] - 88s 884ms/step - loss: 63.1837 - mean_squared_error: 63.3053 - val_loss: 127.8336 - val_mean_squared_error: 126.7774\n",
        "\n",
        "Epoch 00080: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 81/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 63.8167 - mean_squared_error: 63.8167 - val_loss: 146.9602 - val_mean_squared_error: 122.1801\n",
        "\n",
        "Epoch 00081: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 82/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 63.1123 - mean_squared_error: 63.1123 - val_loss: 173.5235 - val_mean_squared_error: 146.5066\n",
        "\n",
        "Epoch 00082: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 83/100\n",
        "100/100 [==============================] - 87s 866ms/step - loss: 63.3223 - mean_squared_error: 63.2971 - val_loss: 116.7359 - val_mean_squared_error: 131.4644\n",
        "\n",
        "Epoch 00083: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 84/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 64.1811 - mean_squared_error: 64.1811 - val_loss: 181.8527 - val_mean_squared_error: 132.1009\n",
        "\n",
        "Epoch 00084: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 85/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 64.0560 - mean_squared_error: 64.2080 - val_loss: 138.5461 - val_mean_squared_error: 128.6714\n",
        "\n",
        "Epoch 00085: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 86/100\n",
        "100/100 [==============================] - 86s 864ms/step - loss: 63.1486 - mean_squared_error: 62.8229 - val_loss: 179.6903 - val_mean_squared_error: 121.4984\n",
        "\n",
        "Epoch 00086: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 87/100\n",
        "100/100 [==============================] - 87s 870ms/step - loss: 65.2112 - mean_squared_error: 65.2112 - val_loss: 81.2447 - val_mean_squared_error: 130.7987\n",
        "\n",
        "Epoch 00087: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 88/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 68.4434 - mean_squared_error: 68.3041 - val_loss: 156.2509 - val_mean_squared_error: 132.8099\n",
        "\n",
        "Epoch 00088: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 89/100\n",
        "100/100 [==============================] - 87s 871ms/step - loss: 65.2679 - mean_squared_error: 65.2679 - val_loss: 105.6682 - val_mean_squared_error: 122.3585\n",
        "\n",
        "Epoch 00089: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 90/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 64.8955 - mean_squared_error: 64.9007 - val_loss: 57.0386 - val_mean_squared_error: 124.4040\n",
        "\n",
        "Epoch 00090: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 91/100\n",
        "100/100 [==============================] - 86s 863ms/step - loss: 63.7957 - mean_squared_error: 63.8949 - val_loss: 119.1728 - val_mean_squared_error: 115.5049\n",
        "\n",
        "Epoch 00091: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 92/100\n",
        "100/100 [==============================] - 88s 881ms/step - loss: 67.7643 - mean_squared_error: 67.7643 - val_loss: 183.5301 - val_mean_squared_error: 122.5895\n",
        "\n",
        "Epoch 00092: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 93/100\n",
        "100/100 [==============================] - 86s 865ms/step - loss: 63.1020 - mean_squared_error: 62.8378 - val_loss: 128.1474 - val_mean_squared_error: 150.3210\n",
        "\n",
        "Epoch 00093: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 94/100\n",
        "100/100 [==============================] - 87s 867ms/step - loss: 64.2218 - mean_squared_error: 64.2911 - val_loss: 112.2486 - val_mean_squared_error: 130.9424\n",
        "\n",
        "Epoch 00094: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 95/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 64.3317 - mean_squared_error: 64.4496 - val_loss: 193.1489 - val_mean_squared_error: 135.3119\n",
        "\n",
        "Epoch 00095: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 96/100\n",
        "100/100 [==============================] - 86s 862ms/step - loss: 62.8766 - mean_squared_error: 62.8766 - val_loss: 84.4813 - val_mean_squared_error: 121.9833\n",
        "\n",
        "Epoch 00096: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 97/100\n",
        "100/100 [==============================] - 86s 861ms/step - loss: 62.0849 - mean_squared_error: 62.0849 - val_loss: 121.7348 - val_mean_squared_error: 117.6836\n",
        "\n",
        "Epoch 00097: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 98/100\n",
        "100/100 [==============================] - 86s 860ms/step - loss: 63.0646 - mean_squared_error: 63.0488 - val_loss: 118.9611 - val_mean_squared_error: 121.4331\n",
        "\n",
        "Epoch 00098: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 99/100\n",
        "100/100 [==============================] - 90s 900ms/step - loss: 62.6711 - mean_squared_error: 62.5150 - val_loss: 149.5496 - val_mean_squared_error: 134.3480\n",
        "\n",
        "Epoch 00099: val_mean_squared_error did not improve from 110.34821\n",
        "Epoch 100/100\n",
        "100/100 [==============================] - 86s 858ms/step - loss: 62.0454 - mean_squared_error: 62.0453 - val_loss: 141.8200 - val_mean_squared_error: 142.0648\n",
        "\n",
        "Epoch 00100: val_mean_squared_error did not improve from 110.34821"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg150aT2JOvt"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"douglas_rodando_regressao_4.h5\",\n",
        "                             monitor='val_mean_squared_error',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto',\n",
        "                             period=1)\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "modelrecuperado= load_model('douglas_rodando_regressao_3.h5')\n",
        "\n",
        "for layer in modelrecuperado.layers[:18]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "hist = modelrecuperado.fit_generator(steps_per_epoch=100,\n",
        "                           generator=traindata,\n",
        "                           validation_data= valdata,\n",
        "                           validation_steps=100,\n",
        "                           epochs=200,\n",
        "                           callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ1lfbml50wt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}