{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN76HaGi9rd6p9iV3VGqld3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WEBAAA3/experimentos/blob/main/SegmentAnything.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "#!pip install   'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJq4XcekqfBc",
        "outputId": "cb673d76-16f5-46b7-bcda-5baaed5c4bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.0+cu118\n",
            "Torchvision version: 0.15.1+cu118\n",
            "CUDA is available: False\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-9i8oaz_u\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-9i8oaz_u\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "  Downloading https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth (2564.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 GB\u001b[0m \u001b[31m362.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download( 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "Gegpv5epwv4M",
        "outputId": "15efee0e-eff2-42a5-95a6-cdf38bd23c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d7f42a12a033>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "HUZ9jM8on2Y6",
        "outputId": "bf61f4a4-8fc6-4e90-df50-bc6efb261505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.0+cu118\n",
            "Torchvision version: 0.15.1+cu118\n",
            "CUDA is available: False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9133ade058c0>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msegment_anything\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msam_model_registry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamAutomaticMaskGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segment_anything'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "image = cv2.imread('houses.jpg')  #Try houses.jpg or neurons.jpg\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "\n",
        "#There are several tunable parameters in automatic mask generation that control\n",
        "# how densely points are sampled and what the thresholds are for removing low\n",
        "# quality or duplicate masks. Additionally, generation can be automatically\n",
        "# run on crops of the image to get improved performance on smaller objects,\n",
        "# and post-processing can remove stray pixels and holes.\n",
        "# Here is an example configuration that samples more masks:\n",
        "#https://github.com/facebookresearch/segment-anything/blob/9e1eb9fdbc4bca4cd0d948b8ae7fe505d9f4ebc7/segment_anything/automatic_mask_generator.py#L35\n",
        "\n",
        "#Rerun the following with a few settings, ex. 0.86 & 0.9 for iou_thresh\n",
        "# and 0.92 and 0.96 for score_thresh\n",
        "\n",
        "mask_generator_ = SamAutomaticMaskGenerator(\n",
        "    model=sam,\n",
        "    points_per_side=32,\n",
        "    pred_iou_thresh=0.9,\n",
        "    stability_score_thresh=0.96,\n",
        "    crop_n_layers=1,\n",
        "    crop_n_points_downscale_factor=2,\n",
        "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
        ")\n",
        "\n",
        "masks = mask_generator_.generate(image)\n",
        "\n",
        "print(len(masks))\n",
        "\n",
        "\n",
        "\n",
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "    polygons = []\n",
        "    color = []\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        img = np.ones((m.shape[0], m.shape[1], 3))\n",
        "        color_mask = np.random.random((1, 3)).tolist()[0]\n",
        "        for i in range(3):\n",
        "            img[:,:,i] = color_mask[i]\n",
        "        ax.imshow(np.dstack((img, m*0.35)))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "show_anns(masks)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:\n",
        "segmentation : the mask\n",
        "area : the area of the mask in pixels\n",
        "bbox : the boundary box of the mask in XYWH format\n",
        "predicted_iou : the model's own prediction for the quality of the mask\n",
        "point_coords : the sampled input point that generated this mask\n",
        "stability_score : an additional measure of mask quality\n",
        "crop_box : the crop of the image used to generate this mask in XYWH format\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "l9h-h-hLvqT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('houses.jpg')  #Try houses.jpg or neurons.jpg\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "\n",
        "#There are several tunable parameters in automatic mask generation that control\n",
        "# how densely points are sampled and what the thresholds are for removing low\n",
        "# quality or duplicate masks. Additionally, generation can be automatically\n",
        "# run on crops of the image to get improved performance on smaller objects,\n",
        "# and post-processing can remove stray pixels and holes.\n",
        "# Here is an example configuration that samples more masks:\n",
        "#https://github.com/facebookresearch/segment-anything/blob/9e1eb9fdbc4bca4cd0d948b8ae7fe505d9f4ebc7/segment_anything/automatic_mask_generator.py#L35\n",
        "\n",
        "#Rerun the following with a few settings, ex. 0.86 & 0.9 for iou_thresh\n",
        "# and 0.92 and 0.96 for score_thresh\n",
        "\n",
        "mask_generator_ = SamAutomaticMaskGenerator(\n",
        "    model=sam,\n",
        "    points_per_side=32,\n",
        "    pred_iou_thresh=0.9,\n",
        "    stability_score_thresh=0.96,\n",
        "    crop_n_layers=1,\n",
        "    crop_n_points_downscale_factor=2,\n",
        "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
        ")\n",
        "\n",
        "masks = mask_generator_.generate(image)\n",
        "\n",
        "print(len(masks))\n",
        "\n",
        "\n",
        "\n",
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "    polygons = []\n",
        "    color = []\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        img = np.ones((m.shape[0], m.shape[1], 3))\n",
        "        color_mask = np.random.random((1, 3)).tolist()[0]\n",
        "        for i in range(3):\n",
        "            img[:,:,i] = color_mask[i]\n",
        "        ax.imshow(np.dstack((img, m*0.35)))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "show_anns(masks)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:\n",
        "segmentation : the mask\n",
        "area : the area of the mask in pixels\n",
        "bbox : the boundary box of the mask in XYWH format\n",
        "predicted_iou : the model's own prediction for the quality of the mask\n",
        "point_coords : the sampled input point that generated this mask\n",
        "stability_score : an additional measure of mask quality\n",
        "crop_box : the crop of the image used to generate this mask in XYWH format\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AkKXxBfBn7n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYdE7HlPn7iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYhDeJNFn7cM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}